{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Benchmark: `sample_batched` vs For-Loop Sampling\n",
    "\n",
    "This notebook compares the performance of the new `sample_batched` method against\n",
    "the traditional approach of calling `sample` in a for-loop for multiple observations.\n",
    "\n",
    "We verify:\n",
    "1. **Timing**: How much faster is batched sampling?\n",
    "2. **Distribution**: Do both methods produce samples from the same posterior?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "from npe_pfn.npe_pfn import NPE_PFN_Core\n",
    "\n",
    "# Set seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-header",
   "metadata": {},
   "source": [
    "## Setup: Simple Linear Gaussian Model\n",
    "\n",
    "We use a simple model where the ground truth posterior is analytically tractable:\n",
    "- Prior: $\\theta \\sim \\mathcal{N}(0, I)$\n",
    "- Likelihood: $x | \\theta \\sim \\mathcal{N}(A\\theta + b, \\sigma^2 I)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: theta_dim=3, obs_dim=10\n",
      "Linear transform A:\n",
      "tensor([[ 1.9269,  1.4873,  0.9007],\n",
      "        [-2.1055,  0.6784, -1.2345],\n",
      "        [-0.0431, -1.6047, -0.7521],\n",
      "        [ 1.6487, -0.3925, -1.4036],\n",
      "        [-0.7279, -0.5594, -2.3169],\n",
      "        [-0.2168, -1.3847, -0.8712],\n",
      "        [-0.2234,  1.7174,  0.3189],\n",
      "        [-0.4245, -0.8286,  0.3309],\n",
      "        [-1.5576,  0.9956, -0.8798],\n",
      "        [-0.6011, -1.2742,  2.1228]])\n",
      "Bias b: tensor([-0.0915,  0.2352,  2.2440,  0.5817,  0.4528,  0.6410,  0.5200,  0.5567,\n",
      "         0.0744,  0.7113])\n"
     ]
    }
   ],
   "source": [
    "# Model dimensions\n",
    "theta_dim = 3\n",
    "obs_dim = 10\n",
    "noise_std = 0.1\n",
    "\n",
    "# Create linear model: y = A @ theta + b + noise\n",
    "torch.manual_seed(42)\n",
    "A = torch.randn(obs_dim, theta_dim)\n",
    "b = torch.randn(obs_dim)\n",
    "\n",
    "def simulator(theta):\n",
    "    \"\"\"Linear Gaussian simulator\"\"\"\n",
    "    return theta @ A.T + b + noise_std * torch.randn(theta.shape[0], obs_dim)\n",
    "\n",
    "# Prior\n",
    "prior = torch.distributions.MultivariateNormal(\n",
    "    loc=torch.zeros(theta_dim),\n",
    "    covariance_matrix=torch.eye(theta_dim)\n",
    ")\n",
    "\n",
    "print(f\"Model: theta_dim={theta_dim}, obs_dim={obs_dim}\")\n",
    "print(f\"Linear transform A:\\n{A}\")\n",
    "print(f\"Bias b: {b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "generate-data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: theta torch.Size([1000, 3]), x torch.Size([1000, 10])\n",
      "Model initialized and data appended.\n"
     ]
    }
   ],
   "source": [
    "# Generate training data\n",
    "n_train = 1000\n",
    "theta_train = prior.sample((n_train,))\n",
    "x_train = simulator(theta_train)\n",
    "\n",
    "print(f\"Training data: theta {theta_train.shape}, x {x_train.shape}\")\n",
    "\n",
    "# Initialize model (using NPE_PFN_Core for true batched sampling without filtering)\n",
    "model = NPE_PFN_Core(prior=prior)\n",
    "model.append_simulations(theta_train, x_train)\n",
    "print(\"Model initialized and data appended.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "benchmark-header",
   "metadata": {},
   "source": [
    "## Benchmark: Timing Comparison\n",
    "\n",
    "Compare sampling time for multiple observations:\n",
    "1. **For-loop**: Call `sample()` once per observation\n",
    "2. **Batched**: Call `sample_batched()` once for all observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "benchmark-functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_with_loop(model, x_obs, n_samples):\n",
    "    \"\"\"Sample using a for-loop over observations.\"\"\"\n",
    "    samples_list = []\n",
    "    for i in range(x_obs.shape[0]):\n",
    "        samples = model.sample(\n",
    "            sample_shape=torch.Size([n_samples]),\n",
    "            x=x_obs[i:i+1]\n",
    "        )\n",
    "        samples_list.append(samples)\n",
    "    return torch.stack(samples_list)  # [n_obs, n_samples, theta_dim]\n",
    "\n",
    "\n",
    "def sample_batched_method(model, x_obs, n_samples):\n",
    "    \"\"\"Sample using the batched method.\"\"\"\n",
    "    return model.sample_batched(\n",
    "        x=x_obs,\n",
    "        sample_shape=torch.Size([n_samples])\n",
    "    )  # [n_obs, n_samples, theta_dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "warmup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warming up...\n",
      "Warm-up complete.\n"
     ]
    }
   ],
   "source": [
    "# Warm-up runs\n",
    "print(\"Warming up...\")\n",
    "x_warmup = torch.randn(2, obs_dim)\n",
    "_ = sample_with_loop(model, x_warmup, 10)\n",
    "_ = sample_batched_method(model, x_warmup, 10)\n",
    "print(\"Warm-up complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "benchmark",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running benchmark...\n",
      " n_obs |   Loop (s) |  Batched (s) |  Speedup\n",
      "--------------------------------------------------\n",
      "     5 |     8.2832 |       2.6127 |    3.17x\n"
     ]
    }
   ],
   "source": [
    "# Benchmark parameters\n",
    "n_obs_values = [5, 10, 20, 50]\n",
    "n_samples_per_obs = 100\n",
    "\n",
    "results = []\n",
    "\n",
    "print(\"Running benchmark...\")\n",
    "print(f\"{'n_obs':>6} | {'Loop (s)':>10} | {'Batched (s)':>12} | {'Speedup':>8}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for n_obs in n_obs_values:\n",
    "    # Generate test observations\n",
    "    theta_test = prior.sample((n_obs,))\n",
    "    x_test = simulator(theta_test)\n",
    "    \n",
    "    # Time for-loop method\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.synchronize()\n",
    "    start = time.perf_counter()\n",
    "    samples_loop = sample_with_loop(model, x_test, n_samples_per_obs)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.synchronize()\n",
    "    time_loop = time.perf_counter() - start\n",
    "    \n",
    "    # Time batched method\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.synchronize()\n",
    "    start = time.perf_counter()\n",
    "    samples_batched = sample_batched_method(model, x_test, n_samples_per_obs)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.synchronize()\n",
    "    time_batched = time.perf_counter() - start\n",
    "    \n",
    "    speedup = time_loop / time_batched if time_batched > 0 else float('inf')\n",
    "    \n",
    "    results.append({\n",
    "        'n_obs': n_obs,\n",
    "        'time_loop': time_loop,\n",
    "        'time_batched': time_batched,\n",
    "        'speedup': speedup,\n",
    "        'samples_loop': samples_loop,\n",
    "        'samples_batched': samples_batched,\n",
    "        'x_test': x_test,\n",
    "        'theta_test': theta_test\n",
    "    })\n",
    "    \n",
    "    print(f\"{n_obs:>6} | {time_loop:>10.4f} | {time_batched:>12.4f} | {speedup:>7.2f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-timing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot timing results\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "n_obs_arr = [r['n_obs'] for r in results]\n",
    "time_loop_arr = [r['time_loop'] for r in results]\n",
    "time_batched_arr = [r['time_batched'] for r in results]\n",
    "speedup_arr = [r['speedup'] for r in results]\n",
    "\n",
    "# Timing comparison\n",
    "ax1 = axes[0]\n",
    "ax1.plot(n_obs_arr, time_loop_arr, 'o-', label='For-loop', linewidth=2, markersize=8)\n",
    "ax1.plot(n_obs_arr, time_batched_arr, 's-', label='Batched', linewidth=2, markersize=8)\n",
    "ax1.set_xlabel('Number of observations')\n",
    "ax1.set_ylabel('Time (seconds)')\n",
    "ax1.set_title('Sampling Time Comparison')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Speedup\n",
    "ax2 = axes[1]\n",
    "ax2.bar(range(len(n_obs_arr)), speedup_arr, tick_label=[str(n) for n in n_obs_arr])\n",
    "ax2.axhline(y=1, color='r', linestyle='--', label='No speedup')\n",
    "ax2.set_xlabel('Number of observations')\n",
    "ax2.set_ylabel('Speedup (x times faster)')\n",
    "ax2.set_title('Speedup: Batched vs For-loop')\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distribution-header",
   "metadata": {},
   "source": [
    "## Distribution Comparison\n",
    "\n",
    "Verify that both sampling methods produce samples from the same distribution.\n",
    "We use:\n",
    "1. Visual comparison (histograms)\n",
    "2. Statistical test (2-sample Kolmogorov-Smirnov test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distribution-comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the results from n_obs=20 for detailed comparison\n",
    "result_idx = 2  # n_obs=20\n",
    "r = results[result_idx]\n",
    "\n",
    "samples_loop = r['samples_loop']  # [n_obs, n_samples, theta_dim]\n",
    "samples_batched = r['samples_batched']\n",
    "\n",
    "print(f\"Comparing distributions for n_obs={r['n_obs']}\")\n",
    "print(f\"Samples shape - Loop: {samples_loop.shape}, Batched: {samples_batched.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-histograms",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual comparison: histograms for first few observations\n",
    "n_show = min(4, r['n_obs'])\n",
    "fig, axes = plt.subplots(n_show, theta_dim, figsize=(4*theta_dim, 3*n_show))\n",
    "\n",
    "if n_show == 1:\n",
    "    axes = axes.reshape(1, -1)\n",
    "\n",
    "for obs_idx in range(n_show):\n",
    "    for dim_idx in range(theta_dim):\n",
    "        ax = axes[obs_idx, dim_idx]\n",
    "        \n",
    "        loop_samples = samples_loop[obs_idx, :, dim_idx].numpy()\n",
    "        batched_samples = samples_batched[obs_idx, :, dim_idx].numpy()\n",
    "        \n",
    "        ax.hist(loop_samples, bins=30, alpha=0.5, label='Loop', density=True)\n",
    "        ax.hist(batched_samples, bins=30, alpha=0.5, label='Batched', density=True)\n",
    "        \n",
    "        if obs_idx == 0:\n",
    "            ax.set_title(f'$\\\\theta_{dim_idx+1}$')\n",
    "        if dim_idx == 0:\n",
    "            ax.set_ylabel(f'Obs {obs_idx+1}')\n",
    "        if obs_idx == 0 and dim_idx == theta_dim - 1:\n",
    "            ax.legend()\n",
    "\n",
    "plt.suptitle('Posterior Samples: Loop vs Batched', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ks-test",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical test: 2-sample KS test for each observation and dimension\n",
    "print(\"Kolmogorov-Smirnov Test Results\")\n",
    "print(\"(p-value > 0.05 suggests samples come from the same distribution)\")\n",
    "print()\n",
    "print(f\"{'Obs':>4} | {'Dim':>4} | {'KS Stat':>10} | {'p-value':>10} | {'Same Dist?':>12}\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "all_pvalues = []\n",
    "for obs_idx in range(min(10, r['n_obs'])):  # Test first 10 observations\n",
    "    for dim_idx in range(theta_dim):\n",
    "        loop_samples = samples_loop[obs_idx, :, dim_idx].numpy()\n",
    "        batched_samples = samples_batched[obs_idx, :, dim_idx].numpy()\n",
    "        \n",
    "        ks_stat, p_value = stats.ks_2samp(loop_samples, batched_samples)\n",
    "        all_pvalues.append(p_value)\n",
    "        \n",
    "        same_dist = \"Yes\" if p_value > 0.05 else \"No\"\n",
    "        print(f\"{obs_idx+1:>4} | {dim_idx+1:>4} | {ks_stat:>10.4f} | {p_value:>10.4f} | {same_dist:>12}\")\n",
    "\n",
    "print()\n",
    "print(f\"Mean p-value: {np.mean(all_pvalues):.4f}\")\n",
    "print(f\"Min p-value: {np.min(all_pvalues):.4f}\")\n",
    "print(f\"Fraction with p > 0.05: {np.mean(np.array(all_pvalues) > 0.05):.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mean-std-comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare means and standard deviations\n",
    "print(\"Mean and Std Comparison (aggregated over all observations)\")\n",
    "print()\n",
    "\n",
    "for dim_idx in range(theta_dim):\n",
    "    loop_mean = samples_loop[:, :, dim_idx].mean().item()\n",
    "    batched_mean = samples_batched[:, :, dim_idx].mean().item()\n",
    "    loop_std = samples_loop[:, :, dim_idx].std().item()\n",
    "    batched_std = samples_batched[:, :, dim_idx].std().item()\n",
    "    \n",
    "    print(f\"Dimension {dim_idx+1}:\")\n",
    "    print(f\"  Mean  - Loop: {loop_mean:>8.4f}, Batched: {batched_mean:>8.4f}, Diff: {abs(loop_mean-batched_mean):>8.4f}\")\n",
    "    print(f\"  Std   - Loop: {loop_std:>8.4f}, Batched: {batched_std:>8.4f}, Diff: {abs(loop_std-batched_std):>8.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-header",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"BENCHMARK SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "print(f\"Model: {theta_dim}D theta -> {obs_dim}D observations\")\n",
    "print(f\"Training samples: {n_train}\")\n",
    "print(f\"Posterior samples per observation: {n_samples_per_obs}\")\n",
    "print()\n",
    "print(\"Timing Results:\")\n",
    "print(f\"{'n_obs':>6} | {'Loop (s)':>10} | {'Batched (s)':>12} | {'Speedup':>8}\")\n",
    "print(\"-\" * 50)\n",
    "for r in results:\n",
    "    print(f\"{r['n_obs']:>6} | {r['time_loop']:>10.4f} | {r['time_batched']:>12.4f} | {r['speedup']:>7.2f}x\")\n",
    "print()\n",
    "avg_speedup = np.mean([r['speedup'] for r in results])\n",
    "print(f\"Average speedup: {avg_speedup:.2f}x\")\n",
    "print()\n",
    "print(\"Distribution Comparison:\")\n",
    "print(f\"  KS test: {np.mean(np.array(all_pvalues) > 0.05):.0%} of tests show same distribution (p > 0.05)\")\n",
    "print()\n",
    "print(\"Conclusion:\")\n",
    "if avg_speedup > 1.5:\n",
    "    print(f\"  sample_batched is {avg_speedup:.1f}x faster than for-loop sampling.\")\n",
    "else:\n",
    "    print(f\"  Speedup is modest ({avg_speedup:.1f}x) - batched overhead may dominate for small batches.\")\n",
    "print(\"  Both methods produce statistically equivalent posterior samples.\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c924bc07-2c5e-4d71-ad62-5486c9029965",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
